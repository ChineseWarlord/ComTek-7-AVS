{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise Description:\n",
    "\n",
    "Perform classification for the entire MNIST dataset based on the algorithms introduced: Use LDA for dimensionality reduction to 2 or 9 dimensions, classify the dimension-reduced data and compare this classification performance with that of using PCA\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.io import loadmat\n",
    "from scipy.stats import multivariate_normal\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import svm\n",
    "import time\n",
    "\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA\n",
    "from sklearn.metrics import (\n",
    "    confusion_matrix,\n",
    "    ConfusionMatrixDisplay,\n",
    "    classification_report,\n",
    "    accuracy_score\n",
    ")\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neural_network import MLPClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 7: Support Vector Machine (SVM)\n",
    "\n",
    "Perform classification for the entire MNIST dataset by using SVMs, e.g. functions in Scikit-learn or Matlab.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data training and testing data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_set: \n",
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]], shape: (60000, 784)\n",
      "train_targets: \n",
      "[0 0 0 ... 9 9 9], shape: (60000,)\n",
      "test_set: \n",
      "[[0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]], shape: (10000, 784)\n",
      "test_targets: \n",
      "[0 0 0 ... 9 9 9], shape: (10000,)\n"
     ]
    }
   ],
   "source": [
    "def create_complete_datasets(data_dict):\n",
    "    '''\n",
    "    Function for creating complete training and test sets containing\n",
    "    all classes.\n",
    "    '''\n",
    "    #Empty list\n",
    "    trainset = []\n",
    "    traintargets =[]\n",
    "    testset = []\n",
    "    testtargets =[]\n",
    "    \n",
    "    #For each class\n",
    "    for i in range(10):\n",
    "        trainset.append(data_dict[\"train%d\"%i])\n",
    "        traintargets.append(np.full(len(data_dict[\"train%d\"%i]),i))\n",
    "        testset.append(data_dict[\"test%d\"%i])\n",
    "        testtargets.append(np.full(len(data_dict[\"test%d\"%i]),i))\n",
    "    \n",
    "    #Concatenate into to complete datasets\n",
    "    trainset = np.concatenate(trainset)\n",
    "    traintargets = np.concatenate(traintargets)\n",
    "    testset = np.concatenate(testset)\n",
    "    testtargets = np.concatenate(testtargets)\n",
    "    return trainset, traintargets, testset, testtargets\n",
    "\n",
    "# Data path\n",
    "data_path = \"../Data/\"\n",
    "file = data_path+\"mnist_all.mat\"\n",
    "data = loadmat(file)\n",
    "\n",
    "#Complete training and test sets\n",
    "train_set, train_targets, test_set, test_targets = create_complete_datasets(data)\n",
    "\n",
    "# Scale the data\n",
    "train_set = StandardScaler().fit_transform(train_set)\n",
    "test_set = StandardScaler().fit_transform(test_set)\n",
    "\n",
    "print(f\"train_set: \\n{train_set}, shape: {train_set.shape}\")\n",
    "print(f\"train_targets: \\n{train_targets}, shape: {train_targets.shape}\")\n",
    "print(f\"test_set: \\n{test_set}, shape: {test_set.shape}\")\n",
    "print(f\"test_targets: \\n{test_targets}, shape: {test_targets.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create and fit SVM on training data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def separate_data(data,n):\n",
    "    data_sep = []\n",
    "    for i in range(n+1):\n",
    "        data_sep.append(data[train_targets == i])\n",
    "        \n",
    "    return data_sep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use sklearn to fit data\n",
    "clf_svm = svm.SVC()\n",
    "clf_svm.fit(train_set,train_targets)\n",
    "\n",
    "# Choose n components\n",
    "n_components = 9\n",
    "\n",
    "# PCA\n",
    "pca = PCA(n_components=n_components)\n",
    "pca_transform_train = pca.fit_transform(train_set)\n",
    "pca_transform_test = pca.transform(test_set)\n",
    "svm_pca = svm.SVC()\n",
    "svm_pca.fit(pca_transform_train,train_targets)\n",
    "\n",
    "# LDA\n",
    "lda = LDA(n_components=n_components)\n",
    "lda_transform_train = lda.fit_transform(train_set)\n",
    "lda_transform_test = lda.transform(test_set)\n",
    "svm_lda = svm.SVC()\n",
    "svm_lda.fit(lda_transform_train,train_targets)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVC()\n"
     ]
    }
   ],
   "source": [
    "# Separating data\n",
    "data1 = separate_data(pca_transform,pca_transform.shape[1])\n",
    "data2 = separate_data(lda_transform,lda_transform.shape[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test model on test set\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'SVC' object has no attribute 'accuracy_score'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32mg:\\Nextcloud\\7th Semester Project\\ComTek-7-AVS\\Lecture 7\\Sim\\exercise.ipynb Cell 11\u001b[0m line \u001b[0;36m3\n\u001b[0;32m      <a href='vscode-notebook-cell:/g%3A/Nextcloud/7th%20Semester%20Project/ComTek-7-AVS/Lecture%207/Sim/exercise.ipynb#X12sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39m# What is the accuracy on the test set?\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/g%3A/Nextcloud/7th%20Semester%20Project/ComTek-7-AVS/Lecture%207/Sim/exercise.ipynb#X12sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m predict_svm \u001b[39m=\u001b[39m clf_svm\u001b[39m.\u001b[39mpredict(test_set)\n\u001b[1;32m----> <a href='vscode-notebook-cell:/g%3A/Nextcloud/7th%20Semester%20Project/ComTek-7-AVS/Lecture%207/Sim/exercise.ipynb#X12sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m accuracy_svm \u001b[39m=\u001b[39m clf_svm\u001b[39m.\u001b[39;49maccuracy_score()\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'SVC' object has no attribute 'accuracy_score'"
     ]
    }
   ],
   "source": [
    "# What is the accuracy on the test set?\n",
    "predict_svm = clf_svm.predict(test_set)\n",
    "accuracy_svm = clf_svm.accuracy_score()\n",
    "score_svm = clf_svm.score(test_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot Confusion matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Does the confusion matrix show us any insights about the model performance?\n",
    "cm_svm = confusion_matrix(test_targets,predict_svm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparing with PCA/LDA\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# How does SVM compare to PCA and LDA (compare confusion matrices)\n",
    "cm_svm_pca = confusion_matrix(test_targets, svm_pca.predict(pca_transform_test))\n",
    "cm_svm_lda = confusion_matrix(test_targets, svm_lda.predict(lda_transform_test))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
