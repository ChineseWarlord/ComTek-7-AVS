{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 1\n",
    "* Use the biker.png template from Exercise materials to do mean shift tracking in the traffic video in Exercise materials. (Hint: use OpenCV's calcBackProject() function to produce a similarity image for mean shift - see this mean shift tutorial for more pointers)\n",
    "* Note that for mean shift tracking you need to provide an initial tracking window manually, and the biker only shows up from frame 114, so wait until then to start tracking.\n",
    "* What happens when the biker disappears over the horizon? Why?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing libraries & packages\n",
    "import numpy as np\n",
    "import cv2 as cv\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import glob\n",
    "import sys\n",
    "\n",
    "# Define data path + output folder\n",
    "data = \"../Data/\"\n",
    "output = \"output/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully exited!\n"
     ]
    }
   ],
   "source": [
    "# Initialize video capture object\n",
    "cap = cv.VideoCapture(data+\"slow_traffic_small.mp4\")\n",
    "\n",
    "frames = []\n",
    "while(1):\n",
    "    ret, frame = cap.read()\n",
    "    frames.append(frame)\n",
    "    \n",
    "    cv.imshow(\"Frames\",frame)\n",
    "    k = cv.waitKey(30) & 0xff\n",
    "    if k == 27:\n",
    "        break\n",
    "    elif len(frames) >= 114:\n",
    "        break\n",
    "\n",
    "# Save frame 114\n",
    "cv.imwrite(output+\"frame114.png\",frames[113])    \n",
    "cv.destroyAllWindows()   \n",
    "print(\"Successfully exited!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize video capture object\n",
    "cap = cv.VideoCapture(data+\"slow_traffic_small.mp4\")\n",
    "\n",
    "# Get height and width from data\n",
    "img = cv.imread(data+\"biker.png\")\n",
    "h,w,_ = img.shape\n",
    "\n",
    "# setup initial location of window\n",
    "x, y, w, h = 591, 180, w, h\n",
    "track_window = (x, y, 20, 25)\n",
    "\n",
    "# set up the ROI for tracking\n",
    "frame = cv.imread(output+\"frame114.png\")\n",
    "roi = frame[y:y+h, x:x+w]\n",
    "hsv_roi = cv.cvtColor(roi, cv.COLOR_BGR2HSV)\n",
    "mask = cv.inRange(hsv_roi, np.array((0., 60.,32.)), np.array((180.,255.,255.)))\n",
    "roi_hist = cv.calcHist([hsv_roi],[0],mask,[180],[0,180])\n",
    "cv.normalize(roi_hist,roi_hist,0,255,cv.NORM_MINMAX)\n",
    "\n",
    "# Setup the termination criteria, either 10 iteration or move by at least 1 pt\n",
    "term_crit = ( cv.TERM_CRITERIA_EPS | cv.TERM_CRITERIA_COUNT, 10, 1 )\n",
    "\n",
    "count = 0\n",
    "while(1):\n",
    "    ret, frame = cap.read()\n",
    "    \n",
    "    if ret == True:\n",
    "        if count >= 114:\n",
    "            hsv = cv.cvtColor(frame, cv.COLOR_BGR2HSV)\n",
    "            dst = cv.calcBackProject([hsv],[0],roi_hist,[0,180],1)\n",
    "            \n",
    "            # apply meanshift to get the new location\n",
    "            ret, track_window = cv.meanShift(dst, track_window, term_crit)\n",
    "            \n",
    "            # Draw it on image\n",
    "            x,y,w,h = track_window\n",
    "            img2 = cv.rectangle(frame, (x,y), (x+w,y+h), 255,2)\n",
    "            cv.imshow('img2',img2)\n",
    "            k = cv.waitKey(30) & 0xff\n",
    "            if k == 27:\n",
    "                break\n",
    "        else:\n",
    "            count += 1\n",
    "            cv.imshow('img2',frame)\n",
    "            k = cv.waitKey(30) & 0xff\n",
    "            if k == 27:\n",
    "                break\n",
    "    else:\n",
    "        break\n",
    "    \n",
    "cv.destroyAllWindows()   \n",
    "print(\"Successfully exited!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 2\n",
    "\n",
    "* Use the biker.png template from Exercise materials to do Kalman filter tracking in the traffic video in Exercise materials. \n",
    "Hints: See this Python implementation for pointers. You can define the state as the position and velocity of the biker, and use the output of mean shift or cam shift (or a detection method of your choice) for the measurement update (note: we only measure position!). You will need to define a measurement matrix, a state transition matrix (motion model), as well as covariance matrices for the measurement and process (model) noise. You can start with unit matrices, and experiment with the parameters.\n",
    "* What happens if you skip the measurement step for certain frames?\n",
    "Extra: Visualize the position uncertainty (errorCovPost attribute in OpenCV) as an ellipse. Plot the measured vs. Kalman filtered position over time and compare.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize kalman filter with 4 state variables and 2 measurement variables\n",
    "kalman = cv.KalmanFilter(4,2)\n",
    "kalman.measurementMatrix = np.array([[1,0,0,0],\n",
    "                                     [0,1,0,0]],np.float32) # Setup a 2x4 measurement matrix, maps x and y coordinates to our 4-dimensional state vector\n",
    "\n",
    "kalman.transitionMatrix = np.array([[1,0,1,0],\n",
    "                                    [0,1,0,1],\n",
    "                                    [0,0,1,0],\n",
    "                                    [0,0,0,1]], np.float32) # Setup a 4x4 transition matrix, defines how state vectors evolve from time step 't' to 't+1'\n",
    "                                                     # based on a simple linear motion model, where objects move linearly at constant velocity.\n",
    "                                                     # First two rows map position estimates onto future position estimates. \n",
    "                                                     # Last two rows maintain unchanged predictions about velocities.\n",
    "                                                     \n",
    "kalman.processNoiseCov = np.array([[1, 0, 0, 0],\n",
    "                                   [0, 1, 0, 0],\n",
    "                                   [0, 0, 1, 0],\n",
    "                                   [0, 0, 0, 1]], np.float32) * 0.03 # Setup a 4x4 noise process covariance matrix, represent the uncertainty in the motion model.\n",
    "                                                              # Affects how the kalman filter predicts the next state.\n",
    "                                                              # We setup diagonal matrix scaled by 0.03, meaning we add small errors to each of our 4 variables.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(coord_x,coord_y):\n",
    "    measured = np.array([[np.float32(coord_x)],[np.float32(coord_y)]]) # Create a measurement vector based on object position (x,y)\n",
    "    kalman.correct(measured) # We update the kalman filter's state estimate with the measurement data\n",
    "    predicted = kalman.predict() # We predict coordinates (px,py)\n",
    "    px,py = int(predicted[0]),int(predicted[1]) # We extract the prediction coordinates\n",
    "    return px,py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x: 591, y: 184\n",
      "prediction: (517, 157)\n",
      "x: 586, y: 181\n",
      "prediction: (579, 178)\n",
      "x: 582, y: 179\n",
      "prediction: (611, 188)\n",
      "x: 579, y: 178\n",
      "prediction: (623, 192)\n",
      "x: 577, y: 179\n",
      "prediction: (622, 193)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\simon\\AppData\\Local\\Temp\\ipykernel_19424\\3611102908.py:5: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
      "  px,py = int(predicted[0]),int(predicted[1]) # We extract the prediction coordinates\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x: 577, y: 178\n",
      "prediction: (616, 191)\n",
      "x: 575, y: 178\n",
      "prediction: (607, 188)\n",
      "x: 574, y: 178\n",
      "prediction: (597, 185)\n",
      "x: 574, y: 179\n",
      "prediction: (589, 183)\n",
      "x: 584, y: 182\n",
      "prediction: (588, 183)\n",
      "x: 584, y: 182\n",
      "prediction: (587, 183)\n",
      "x: 585, y: 181\n",
      "prediction: (587, 182)\n",
      "x: 585, y: 181\n",
      "prediction: (586, 182)\n",
      "x: 585, y: 181\n",
      "prediction: (586, 181)\n",
      "x: 582, y: 182\n",
      "prediction: (584, 181)\n",
      "x: 578, y: 181\n",
      "prediction: (580, 181)\n",
      "x: 576, y: 180\n",
      "prediction: (576, 180)\n",
      "x: 575, y: 181\n",
      "prediction: (574, 180)\n",
      "x: 575, y: 181\n",
      "prediction: (572, 180)\n",
      "x: 575, y: 180\n",
      "prediction: (572, 180)\n",
      "x: 575, y: 179\n",
      "prediction: (572, 179)\n",
      "x: 569, y: 176\n",
      "prediction: (569, 177)\n",
      "x: 568, y: 177\n",
      "prediction: (567, 176)\n",
      "x: 568, y: 178\n",
      "prediction: (565, 176)\n",
      "x: 568, y: 178\n",
      "prediction: (565, 176)\n",
      "x: 563, y: 177\n",
      "prediction: (562, 176)\n",
      "x: 563, y: 177\n",
      "prediction: (561, 176)\n",
      "x: 558, y: 176\n",
      "prediction: (557, 175)\n",
      "x: 556, y: 175\n",
      "prediction: (554, 175)\n",
      "x: 555, y: 174\n",
      "prediction: (552, 173)\n",
      "x: 555, y: 176\n",
      "prediction: (551, 174)\n",
      "x: 555, y: 175\n",
      "prediction: (551, 174)\n",
      "x: 553, y: 174\n",
      "prediction: (551, 173)\n",
      "x: 553, y: 173\n",
      "prediction: (550, 173)\n",
      "x: 552, y: 173\n",
      "prediction: (550, 172)\n",
      "x: 552, y: 173\n",
      "prediction: (550, 172)\n",
      "x: 550, y: 173\n",
      "prediction: (549, 172)\n",
      "x: 546, y: 172\n",
      "prediction: (546, 171)\n",
      "x: 547, y: 172\n",
      "prediction: (545, 171)\n",
      "x: 545, y: 172\n",
      "prediction: (544, 171)\n",
      "x: 545, y: 173\n",
      "prediction: (543, 172)\n",
      "x: 543, y: 174\n",
      "prediction: (542, 173)\n",
      "x: 541, y: 173\n",
      "prediction: (540, 173)\n",
      "x: 539, y: 173\n",
      "prediction: (538, 173)\n",
      "x: 539, y: 173\n",
      "prediction: (537, 173)\n",
      "x: 537, y: 173\n",
      "prediction: (535, 173)\n",
      "x: 536, y: 173\n",
      "prediction: (534, 173)\n",
      "x: 535, y: 173\n",
      "prediction: (533, 173)\n",
      "x: 534, y: 173\n",
      "prediction: (532, 173)\n",
      "x: 532, y: 172\n",
      "prediction: (530, 172)\n",
      "x: 532, y: 172\n",
      "prediction: (530, 172)\n",
      "x: 531, y: 173\n",
      "prediction: (529, 172)\n",
      "x: 529, y: 173\n",
      "prediction: (528, 172)\n",
      "x: 529, y: 173\n",
      "prediction: (527, 172)\n",
      "x: 529, y: 172\n",
      "prediction: (527, 172)\n",
      "x: 528, y: 172\n",
      "prediction: (526, 172)\n",
      "x: 526, y: 172\n",
      "prediction: (525, 171)\n",
      "x: 525, y: 171\n",
      "prediction: (524, 171)\n",
      "x: 525, y: 171\n",
      "prediction: (523, 170)\n",
      "x: 524, y: 171\n",
      "prediction: (523, 170)\n",
      "x: 523, y: 171\n",
      "prediction: (522, 170)\n",
      "x: 522, y: 170\n",
      "prediction: (521, 170)\n",
      "x: 521, y: 170\n",
      "prediction: (520, 169)\n",
      "x: 520, y: 170\n",
      "prediction: (519, 169)\n",
      "x: 519, y: 170\n",
      "prediction: (518, 169)\n",
      "x: 518, y: 170\n",
      "prediction: (517, 169)\n",
      "x: 518, y: 170\n",
      "prediction: (516, 169)\n",
      "x: 516, y: 169\n",
      "prediction: (515, 169)\n",
      "x: 515, y: 169\n",
      "prediction: (514, 168)\n",
      "x: 514, y: 169\n",
      "prediction: (513, 168)\n",
      "x: 514, y: 168\n",
      "prediction: (512, 168)\n",
      "x: 512, y: 168\n",
      "prediction: (511, 167)\n",
      "x: 511, y: 168\n",
      "prediction: (510, 167)\n",
      "x: 510, y: 167\n",
      "prediction: (509, 166)\n",
      "x: 510, y: 167\n",
      "prediction: (508, 166)\n",
      "x: 510, y: 167\n",
      "prediction: (508, 166)\n",
      "x: 509, y: 166\n",
      "prediction: (508, 165)\n",
      "x: 508, y: 166\n",
      "prediction: (507, 165)\n",
      "x: 507, y: 166\n",
      "prediction: (506, 165)\n",
      "x: 506, y: 165\n",
      "prediction: (505, 164)\n",
      "x: 505, y: 165\n",
      "prediction: (504, 164)\n",
      "x: 504, y: 164\n",
      "prediction: (503, 163)\n",
      "x: 503, y: 165\n",
      "prediction: (502, 164)\n",
      "x: 503, y: 165\n",
      "prediction: (501, 164)\n",
      "x: 503, y: 166\n",
      "prediction: (501, 165)\n",
      "x: 502, y: 165\n",
      "prediction: (501, 165)\n",
      "x: 501, y: 164\n",
      "prediction: (500, 164)\n",
      "x: 500, y: 163\n",
      "prediction: (499, 163)\n",
      "x: 499, y: 161\n",
      "prediction: (498, 161)\n",
      "x: 499, y: 163\n",
      "prediction: (498, 161)\n",
      "x: 499, y: 162\n",
      "prediction: (497, 161)\n",
      "x: 496, y: 162\n",
      "prediction: (496, 161)\n",
      "x: 494, y: 162\n",
      "prediction: (494, 161)\n",
      "x: 494, y: 161\n",
      "prediction: (492, 160)\n",
      "x: 493, y: 161\n",
      "prediction: (491, 160)\n",
      "x: 492, y: 160\n",
      "prediction: (490, 159)\n",
      "x: 490, y: 160\n",
      "prediction: (489, 159)\n",
      "x: 489, y: 160\n",
      "prediction: (487, 159)\n",
      "x: 489, y: 159\n",
      "prediction: (487, 158)\n",
      "Successfully exited!\n"
     ]
    }
   ],
   "source": [
    "# Initialize video capture object\n",
    "cap = cv.VideoCapture(data+\"slow_traffic_small.mp4\")\n",
    "\n",
    "# Get height and width from data\n",
    "img = cv.imread(data+\"biker.png\")\n",
    "h,w,_ = img.shape\n",
    "\n",
    "# Setup initial location of window\n",
    "x, y, w, h = 591, 180, w, h\n",
    "track_window = (x, y, 20, 25)\n",
    "\n",
    "# set up the ROI for tracking\n",
    "frame = cv.imread(output+\"frame114.png\")\n",
    "roi = frame[y:y+h, x:x+w]\n",
    "hsv_roi = cv.cvtColor(roi, cv.COLOR_BGR2HSV)\n",
    "#mask = cv.inRange(hsv_roi, np.array((0., 60.,32.)), np.array((180.,255.,255.))) # Original mask\n",
    "mask = cv.inRange(hsv_roi, np.array((10., 36., 68.)), np.array((180.,255.,255.))) # Tried to change some params\n",
    "roi_hist = cv.calcHist([hsv_roi],[0],mask,[180],[0,180])\n",
    "cv.normalize(roi_hist,roi_hist,0,255,cv.NORM_MINMAX)\n",
    "\n",
    "# Setup the termination criteria, either 10 iteration or move by at least 1 pt\n",
    "term_crit = ( cv.TERM_CRITERIA_EPS | cv.TERM_CRITERIA_COUNT, 10, 1 )\n",
    "\n",
    "count = 0\n",
    "while(1):\n",
    "    ret, frame = cap.read()\n",
    "    \n",
    "    if ret == True:\n",
    "        if count >= 114:\n",
    "            hsv = cv.cvtColor(frame, cv.COLOR_BGR2HSV)\n",
    "            dst = cv.calcBackProject([hsv],[0],roi_hist,[0,180],1)\n",
    "            \n",
    "            # Apply meanshift to get the new location\n",
    "            ret, track_window = cv.meanShift(dst,track_window, term_crit)\n",
    "            \n",
    "            # Draw observation on image - in green\n",
    "            x,y,w,h = track_window\n",
    "            img2 = cv.rectangle(frame, (x, y), (x + w, y + h), (0, 255, 0), 2)\n",
    "            print(f\"x: {x}, y: {y}\")\n",
    "            \n",
    "            # Predict coordinates\n",
    "            prediction = predict(x,y)\n",
    "            \n",
    "            # draw predicton on image - in red\n",
    "            img2 = cv.rectangle(frame,(prediction[0],prediction[1]), (prediction[0] + w, prediction[1] + h), (0,0,255), 1)\n",
    "            print(f\"prediction: {prediction}\")\n",
    "            \n",
    "            cv.imshow('img2',img2)\n",
    "            k = cv.waitKey(30) & 0xff\n",
    "            if k == 27:\n",
    "                break\n",
    "        else:\n",
    "            count += 1\n",
    "            cv.imshow('img2',frame)\n",
    "            k = cv.waitKey(30) & 0xff\n",
    "            if k == 27:\n",
    "                break\n",
    "    else:\n",
    "        break\n",
    "    \n",
    "cv.destroyAllWindows()   \n",
    "print(\"Successfully exited!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
